---
title: "Computational Musicology"
author: "Isa Alders"
date: "Period 4"
output: 
    flexdashboard::flex_dashboard:
      storyboard: true
      theme: yeti
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(spotifyr)
spotifyr::get_spotify_access_token()
library(dplyr)
library(flexdashboard)
library(plotly)
library(compmus)
```

### The similarity between my playlist and my mothers 

Growing up I've always listened to a lot of music at home. My parents are all big on music, especially my mom and my stepdad. Before the covid pandemic they used to go to concerts at least twice a month, and listen to music all day (this they still do). We as a family have gone to multiple concerts together, and always send in our lists for the top 2000 (an annual radio show where the listeners can vote for their favourite songs). Me and my mom have noticed that our lists always have many of the same songs on there. Now I actually had the opportunity, I have researched the similarities in the music we listen to. I did this by comparing my "Your Top Songs 2020", "Your Top Songs 2019" and "Your Top Songs 2018" to the ones of my parents account. These are lists Spotify creates for you. They contain the 100 songs you listened to most that specific year. Because some playlists contained duplicates, the total of songs didn't add up to 600 songs, but a little under that. 

My mother shares her Spotify account with her husband, who listens to a lot of classic rock.


```{r playlists, echo=FALSE}
isa <- get_playlist_audio_features("", "2JhcfrBpNKGKB5vut5PIY1")
mh <- get_playlist_audio_features("", "5DCCNsnEiJzi3uzhkMNdkG")


all_music <-
  bind_rows(
    isa %>% mutate(category = "Isa"),
    mh %>% mutate(category = "MH")
  )

```


### Combination {data-commentary-width=305}

```{r combination, echo=FALSE}
combination <- all_music %>%                    # Start with awards.
  ggplot(aes(x = valence, y = energy, size = instrumentalness, col = loudness)) +
    geom_point(alpha = 0.6) +
    facet_wrap(~ category) +
    scale_size_continuous(      # Fine-tune the sizes of each point.
      trans = "exp",            # Use an exp transformation to emphasise loud.
      guide = "legend"
    ) +
  scale_x_continuous(         # Fine-tune the x axis.
      limits = c(0, 1),
      breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
      limits = c(0, 1),
      breaks = c(0, 0.50, 1),
  ) +
  theme_light() +           # Use a simpler theme.
    labs(                       # Make the titles nice.
      x = "Valence",
      y = "Energy",
      colour = "Loudness",
      size = "Instrumentalness"
    ) 
    
combination


```

*** 

In these plots you can see the **energy** plotted against the **valence**. **Color** is used to distinguish the **loudness** of the song. The **size** of the dot shows the **instrumentalness** of the specific song. The two plots are seperated to show the plot of my own playlist on the left, and the music of my parents playlist on the right. The two low-energy and low-valence outliers in my playlist are songs I listen to while studying, both from Ludovico Einaudi. 

Something that did suprise me is the fact that there is not much difference in the loudness between the songs. This suprises me especially because there are a lot of loud, classical rock songs in the playlist of my parents. I don't really know what caused this, but maybe it's just the way spotify implements loudness. You can see that in general, the songs are all quite evenly distributed, so it's hard to draw any real conclusions from this plot.

### Combination 2.0

```{r combination 2.0, echo=FALSE}

all_music %>%
  ggplot(aes(x = energy, fill=category)) +
  geom_histogram() +
  facet_wrap(~ category, scales="free_y")+
  scale_x_continuous(
    limits=c(0,1),
    breaks=c(0,0.5,1)
  )+
  labs(fill='Playlist owner', title='Count of energy per playlist owner') +
  xlab('Energy') +
  ylab("Count")

all_music %>%
  ggplot(aes(x = tempo,  fill=category)) +
  geom_histogram() +
  facet_wrap(~ category)+
  scale_x_continuous(
  limits=c(0,250),
  breaks=c(0,125,250)
  )+
  labs(fill='Playlist owner', title='Count of tempo per playlist owner') +
  xlab('Tempo')+
  ylab("Count")


all_music %>%
  ggplot(aes(x = danceability, fill=category)) +
  geom_histogram() +
  facet_wrap(~ category, scales="free_y")+
  scale_x_continuous(
  limits=c(0,1),
  breaks=c(0,0.5,1)
  )+
  labs(fill='Playlist owner', title='Count of danceability per playlist owner') +
  xlab('Danceability') +
  ylab("Count")
```

*** 

Herkjebr

### Zooming in on a mutual favourite {data-commentary-width=500}

```{r, echo=FALSE}
fleetwood_mac <-
  get_tidy_audio_analysis("5e9TFTbltYBg2xThimr0rU") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

fleetwood_mac_plot <- fleetwood_mac %>%
  mutate(pitches = map(pitches, compmus_normalise, "chebyshev")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
fleetwood_mac_plot
```

*** 

On the left we can see a chromagram of *The Chain* by *Fleetwood Mac*. This is a song both my mom and I have in our playlists. You could say this song is one of the classics in our household, and I thought it would be nice to zoom into this song. What are typical features of a song we both like? We can see that **G#, Ab** and **E** are quite present in this song. 


<object data="https://open.spotify.com/embed/track/5e9TFTbltYBg2xThimr0rU" width="280" height="140">
    <embed src="https://open.spotify.com/embed/track/5e9TFTbltYBg2xThimr0rU" width="280" height="140"></embed>
</object>


### Chordograms

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

fleetwood_mac2 <-
  get_tidy_audio_analysis("5e9TFTbltYBg2xThimr0rU") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

fleetwood_mac2 %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "manhattan",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***

On the left we can see a chordogram of the same song as the last slide: The Chain by FLeetwood Mac. When we look at this chordogram, it seems that **G major** and **D minor** are most present in the song. 

### Self-similarity matrices {data-commentary-width=305}

```{r, echo=FALSE}
arctic_monkeys <-
  get_tidy_audio_analysis("5FVd6KXrgO9B3JPmC8OPst") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  arctic_monkeys %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  arctic_monkeys %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

*** 

These are the self-similarity matrices for **Do I Wanna Know** by the **Arctic Monkeys**, which is also a song that is in both playlits. Just like Fleetwood Mac, the Arctic Monkeys are a true family favourite and we've been to multiple concerts of them together. In the timbre self-similarity matrix, a yellow cross is visible. I haven't figured out what this might be by listening to the song. The song is quite slow and steady. The two matrices are both at bars level, and I used the **aitchison** and **euclidean** normalisation, respectively. 

<object data="https://open.spotify.com/embed/track/5FVd6KXrgO9B3JPmC8OPst" width="280" height="140">
    <embed src="https://open.spotify.com/embed/track/5FVd6KXrgO9B3JPmC8OPst" width="280" height="140"></embed>
</object>

### Tempograms



```{r, echo=FALSE}
deep_purple <- get_tidy_audio_analysis("60ifqqPhbselSwXyGrGyMK")
```


![Tempogram](/Users/Isa/Downloads/000003.png)

---   

**DO NOT SHOW THIS IN CLASS**   
Here we can see the tempogram of the song Soldier of Fortune by Deep purple. This is a song which is not typical at all for my playlist, but can be very typical for my parents, because it is a song my stepfather listens to a lot.


