---
title:  "Discover Weekly's Butterfly Transformation"
author: 'Tosca Beijaert'
date:   'February--March 2020'
output: 
    flexdashboard::flex_dashboard:
        storyboard: true
        theme: united
---

```{r chunk1, setup}

# In order to use these packages, we need to install flexdashboard, plotly, and Cairo.
library(scales)
library(kknn)
library(C50)
library(randomForest)
library(tidyverse)
library(plotly)
library(spotifyr)
library(Cairo)
library(ggplot2)
library(compmus)
source('spotify.R')
library(CGPfunctions)
library(viridis)
library(tidymodels)
library(protoclust)
library(ggdendro)
library(heatmaply)
library(dplyr)
library(egg)


```


### **Will my Discover Weekly evolve into Alex? Feature differeneces between My Favorites, Alex's Favorites and Discover Weekly**{data-commentary-width=305}

```{r chunk10}



# My Spotify Favorites
favorites=get_playlist_audio_features("Tosca Beijaert","16OAuKPZYr8YM4a9n1V6kf")


# Because there were local files in the list, spotify added extra columns, which i removed as the other
# playlists don't have these comments, so it will be useless for compariosn.
favorites=favorites[-c(59:63)]

# We also have to remove the local files, as i cannot  compare them as there is no analysis for these tracks.
favorites=subset(favorites, track.is_local==FALSE) # we delete the local files


# Alex favorites
alex=get_playlist_audio_features("Alexander Keijser","59c8tug3WdwODj6gV0ierq")

# Discover weekly Favorites week 1
discover_weekly1=get_playlist_audio_features("Tosca Beijaert","1RGiBzoNLHf0GkTYRxDhpY")

# Discover weekly favorites week 2

discover_weekly2=get_playlist_audio_features("Tosca Beijaert", "24kpxnb8oyQykp71Gn3sge")

discover_weekly3=get_playlist_audio_features("Tosca Beijaert","1vOSG6EzDsKLNlvRFEhcjF")

discover_weekly4=get_playlist_audio_features("Tosca Beijaert","2XhLwoBvdUK38ROYUwR1Mg")

discover_weekly5=get_playlist_audio_features("Tosca Beijaert","7okC2wt4u0QtdddWp3Li7Q")

discover_weekly6=get_playlist_audio_features("Tosca Beijaert","5YkD0hqRQ1g6R1PVckNSac")

discover_weekly7=get_playlist_audio_features("Tosca Beijaert","67TgsEi6QAM7fb7RB73N2q")

discover_weekly8=get_playlist_audio_features("Tosca Beijaert","4GhJfgljCrnaIbJ30qIabQ")

# Discover weekly 1 & 2 combined (combined playlists)

# discover_weekly_combined_week2=merge(discover_weekly1[6:16],discover_weekly2.1[6:16])
#View(discover_weekly_combined_week2) # WHY DOES THIS NOT WORK???A


# Discover Weekly Archive

discover_weekly_archive=get_playlist_audio_features("Tosca Beijaert", "4jLB65Tpbt91Ta2QrypTFV")




playlists=
  alex %>% mutate(playlist = "Alex") %>%
  bind_rows(favorites %>% mutate(playlist = "Favorites")) %>%
  bind_rows(discover_weekly1%>% mutate(playlist = "Discover Weekly 1"))


# We need some samples of the playlists of the favorites as they are too big.
fav_sample=favorites[sample(nrow(favorites),500),]
alex_sample=alex[sample(nrow(alex),500),]

playlists_sample=
  alex_sample %>% mutate(playlist = "Alex Sample") %>%
  bind_rows(fav_sample %>% mutate(playlist = "Favorites Sample")) %>%
  bind_rows(discover_weekly1%>% mutate(playlist = "Discover Weekly Base"))


# The Plot of 3 variables

playlists_sample %>%
  ggplot(aes(x = energy, y=danceability, col=instrumentalness)) + # Add tempo to size here
  geom_point() +
  geom_rug(size = 0.1)+
  facet_wrap(~ playlist)+
  labs(title='Energy, Danceability & Instrumentalness per Playlist') +
  scale_x_continuous(          # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),  # Use grid-lines for quadrants only.
    minor_breaks = NULL      # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(          # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  theme_classic() +              # Use a simpler them.
  labs(                        # Make the titles nice.
    x = "Energy",
    y = "Danceability",
    colour = "Instrumentalness",
    size="Tempo"
  ) + scale_color_viridis( option = "D")



# Second plot
 ggplot(playlists_sample, aes(energy, danceability, col=playlist))+
   geom_jitter(alpha=0.5)+
   geom_smooth() +
   labs(
     title = "Energy & Danceability per Playlist",
     x = "Energy",
     y = "Danceability",
     col="Playlist"
   )

 # gridExtra::grid.arrange(plot1, plot2, ncol = 1, nrow = 2)

```


***

This project will compare 3 Spotify playlists: My Favourites playlist, the playlist of my boyfriend Alex and my discover weekly. The following points will be examined: 

- 1. Analyses of these playlists show that they differ a lot (see next slide).
- 2. Assuming that discover weekly adapts to what you listen to the most ( [according to this article](https://qz.com/571007/the-magic-that-makes-spotifys-discover-weekly-playlists-so-damn-good/) ), I will perform an experiment where I will listen __ONLY__ to my boyfriends playlist for the coming 8 weeks, to see if my Discover Weekly (and certain features) will start to look more like his playlist. The features that will be looked at are __Danceability__, __Energy__, __Instrumentalness__ and __Tempo__.

On the left we see a plot for Energy, Danceability and Instrumentalness for each playlist, where we use the data of week 1 for discover weekly. The plot wasn't very interpretable when using all the data from Alex's and my playlist (+3000 songs). Thus, 500 songs were randomly sampled from those playlists, to make this plot more clear-cut. We can observe that my Favorite's has more songs which are less danceable than Alex's playlist and discover weekly. And that in general, discover weakly has less of a spread for danceability and energy.

The left plot however is hard to interpret, therefore we could look at just the danceability and energy, seen in the right plot. This shows very clearly that spotify weekly's data isn't very spread. For instance, looking at the green line, we can see that the danceability nor the energy go below 0.3 for discover weekly. However, these two plots don't show us that well how any of the variables are distributed. Thus the next slide will look at histograms showing the distribution per feature.

### **The Baseline differences: Distributions of the features**{data-commentary-width=300}

```{r chunk11}



# MAKING PLOTS.

# We will now start making plots. We want 1 plot that compares the 3 playlists & 1 plot that compares the
# discover weekly playlists over time.

# Comparing the 3 playlists.
# we combine the 3 data sets favorites, alex and discover weekly archive.



# 1. We start with the baseline differences for alex's favourties, my faovrites and discover weekly week 1.

playlists %>%
  ggplot(aes(x = energy, col=playlist)) +
  geom_histogram() +
  facet_wrap(~ playlist, scales="free_y")+
  scale_x_continuous(
    limits=c(0,1),
    breaks=c(0,0.5,1)
  )+
  labs(color='Playlist', title='Energy per Playlist') +
  xlab('Energy') +
  ylab("Count")



playlists %>%
ggplot(aes(x = tempo,  col=playlist)) +
geom_histogram() +
facet_wrap(~ playlist, scales="free_y")+
scale_x_continuous(
limits=c(0,250),
breaks=c(0,125,250)
)+
labs(color='Playlist', title='Tempo per Playlist') +
xlab('Tempo')+
ylab("Count")+
theme_get()


playlists %>%
ggplot(aes(x = danceability, col=playlist)) +
geom_histogram() +
facet_wrap(~ playlist, scales="free_y")+
scale_x_continuous(
limits=c(0,1),
breaks=c(0,0.5,1)
)+
labs(color='Playlist', title='Danceability per Playlist') +
xlab('Danceability') +
ylab("Count")+
theme_get()

playlists %>%
ggplot(aes(x = instrumentalness, col=playlist)) +
geom_histogram() +
facet_wrap(~ playlist, scales="free_y")+
scale_x_continuous(
limits=c(0,1),
breaks=c(0,0.5,1)
)+
labs(color='Playlist', title='Instrumentalness per Playlist') +
xlab('Instumentalness') +
ylab("Count")+
theme_get()



```

***

Here we look at the distributions of the features. For every plot you get a specific feature on the x-axis and the amount on the y-axis. Note that the values of the y-axes differ for the playlists, as discover weekly only has 30 songs and the other 2 have around 3000 songs. These plots clearly show the differences of how the songs are distributed for the different playlists.

- For instance, Discover weekly has less energetic songs than the other two. The tempo mostly lies around 125 bmp, whereas the other 2 are more spread.

- The means per feature (see tables below) show that all values except instrumentalness are lower for discover weekly than for alex's favorites. Therefore it would make sense for these values to increase as we listen more and more to Alex's playlist. What happens to instrumentalness is unclear, as the histograms show that this feature is distributed very differntly from Alex's playlist. Thus the means of the features do not give enough information. The means might not always differ that much, but looking at the distributions, differences can easily be seen. 

Looking at the plots (slide 1) and histograms it is noticed that the playlists are distributed differently. Thus the following hypothis were made regarding the changes in the discover weekly playlist over 8 weeks time (further explanation can be found below the tables):

|  Hypothesis | Discover Weekly After 8 Weeks  |
|---|---|
| Energy  | Will go up  |
|  Tempo |  Will go up |
|  Danceability | Will go up  |
| Instrumentalness  | ?  |

__MEAN VALUES__

**My Favourites**

|Feature   |Mean   |SD   |
|---|---|---|
| Danceability  | 0.567  |0.184   |
| Energy  | 0.636  |  0.265  |
| Instrumentalness  | 0.329   | 0.373  |
| Tempo  |  124  | 31  |


**Discover Weekly 1**

| Feature  |Mean   |SD   |
|---|---|---|
| Danceability  | 0.693   |0.125   |
| Energy  | 0.664   |  0.167  |
| Instrumentalness  | 0.530    | 0.351  |
| Tempo  |   116   | 16   |


**Alex's Favorites**

|Feature   |Mean   |SD   |
|---|---|---|
| Danceability  | 0.717   |0.138   |
| Energy  | 0.681  |  0.184  |
| Instrumentalness  | 0.505  | 0.391  |
| Tempo  |  121 | 19.8   |


__Argumentation__:

From the histograms we can tell that most of Alex's songs are high in energy, therefore we hypothesize that discover weekly will go up in energy. Looking at the histograms, we can see that Alex's favorites have more songs with a higher tempo than discover weekly, therefore we hypothesize this value to go up. Even though by looking at the histograms, the danceability of discover weekly and alex's favorites look about the same, tempo and danceability are highly correlated, therefore we also expect danceability to go up in value. We cannot see big changes in the instrumentalness between discover weekly and alex's playlist, however, I know that alex's playlist has a lot of techno songs, thus a high instrumentalness, therefore we might hypothesize instrumentalness will go up.


### **Zooming in on Alex's least Danceable Song VS Alex's most danceable Song: Larimosa VS Brainstorm!**

```{r chunk3}
# library(png)
# library(grid)
# img <- readPNG("lacrimosa.png")
# grid.raster(img)
library(knitr)
include_graphics("lacrimosa.png")
include_graphics("brainstorm.jpg")
```


***

Before looking at the changes of Disover weekly we will compare these two songs, as they represent Alex's playlist very well, in the sense that a lot of different genres are compiled in his playlist. As they are completely different genres, we will see how different kind of feature analyses will work for the two songs.

After doing some research, I found out that Alex's least danceable song is Lacrimosa, from Amadeus Mozart, which is quite funny as it is one of our favorite classical music songs, which we sing all the time.

<html>
<audio controls>
  <source src="Lacrimosa_Alex.mp3" type="audio/mpeg">
</audio>
</html>

Now I know that Lacrimosa is played in d-minor, which will help us later on. Lacrimosa has some very particular Harmonic orders, for instance for the first few beats: I-II-V-I-II-V. This sequence and an explanation used of the harmonics & emotions of this song can be found in this [video!](https://www.youtube.com/watch?v=D8SD3ToKDsw). Please watch it, even if you only look at the first 6 seconds, it's really interesting!

The other song is called Brainstorm by Special Request. Which is a techno/breakbeat song.

<html>
<audio controls>
  <source src="Brainstorm Special Request.mp3" type="audio/mpeg">
</audio>
</html>



### **Dynamic Time Warping Two Lacrimosa's. That seems to work!**{data-commentary-width=400}

```{r chunk5}
Lacrimosa_Chroma =
    get_tidy_audio_analysis("1UvaZaHkh3D9AkmBrrnbFg") %>%
    select(segments) %>% unnest(segments) %>%
    select(start, duration, pitches)

lacrimosa2 =
    get_tidy_audio_analysis("3oHSL6pt9LpNrQZuQGu9wL") %>%
    select(segments) %>% unnest(segments) %>%
    select(start, duration, pitches)

compmus_long_distance(
    Lacrimosa_Chroma %>% mutate(pitches = map(pitches, compmus_normalise, 'manhattan')), # You only need to change the names of your trakcs, so in this case the tallis and chapelle. Also change your norm to what you want, bv euclidean and change the distances (method)
    lacrimosa2 %>% mutate(pitches = map(pitches, compmus_normalise, 'manhattan')),
    feature = pitches,
    method = 'manhattan') %>%
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    scale_fill_continuous(type = 'viridis', guide = 'none') +
    labs(title= "Dynamic Time Warp",x = 'Alex his Lacrimosa', y = 'My Lacrimosa') +
    theme_classic() # The diagnoal line represent the dynamic time warp.

```

***


Luckily for me, I also have Lacrimosa in my playlist, however mine is a slightly different version from the Choir of King's College, meaning there might be some more polyphonic parts in this version. Also for my version the tempo is a little bit higher and the tuning seems to be a bit tuned down.

__Alex's Lacrimosa by Lisa Beckley:__

<html>
<audio controls>
  <source src="Lacrimosa_Alex.mp3" type="audio/mpeg">
</audio>
</html>


__My Lacrimosa from the Choir of Kings college:__

<html>
<audio controls>
  <source src="Lacrimosa_Tosca.mp3" type="audio/mpeg">
</audio>
</html>

Dynamic Time Warping will be used to compute the most optimal alignment between the two features sequences. As chroma norm and distance measure manhattan was chosen, the other options did not seem to work well for this data. We can see the black line diagonally, expressing the optimal warping path. Meaning that it is possible to align these two different versions, even with the differences in pitch and tempo.


### **SSM matrixes Showing us what's actually going on.**{data-commentary-width=307}

```{r Langzamechunk7}
# The SSM of the Chroma

moments_y=c("Buildup-0 sec","Bass Block-60 sec", "Bass Block + High Heads-100 sec", "Piano-130 sec", "Bass Block + High Heads-190 sec", "Piano-244 sec", "Outro-305 sec") # Vector with label for the x-axis

moments_x=c("Buildup - 0s","Bass Block - 60s", "Bass Block + HH - 100s", "Piano - 130s", "Bass Block + HH - 190s", "Piano - 244s", "Outro - 305s") # Vector with label for the x-axis

Lacrimosa_Chroma %>%
    compmus_self_similarity(pitches, 'cosine') %>%  # Here you can change the secon argument again, meaning you change the distance.
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'B', guide = 'none') +
      theme_classic()+
  labs(title='Lacrimosa Chroma SSM Using Cosine Distance', x="", y="")

Brainstorm_Chroma=
    get_tidy_audio_analysis("4GdOWNJzpTWoKdA4LEbXDa") %>%
    select(segments) %>% unnest(segments) %>%
    select(start, duration, pitches)

SSM_Chroma=Brainstorm_Chroma %>%
    compmus_self_similarity(pitches, 'cosine') %>%  # Here you can change the secon argument again, meaning you change the distance.
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'B', guide = 'none') +
      theme_classic() +
  scale_x_continuous(
    breaks = c(0,60,100,130,190,244,305),  # Use grid-lines for quadrants only.
    labels=moments_x,
    minor_breaks = NULL      # Remove 'minor' grid-lines.
    ) +
  scale_y_continuous(          # Fine-tune the y axis in the same way.
    breaks = c(0,60,100,130,190,244,305),
    labels=moments_y,
    minor_breaks = NULL
  ) +
  labs(title='Brainstorm Chroma SSM Using Cosine Distance', x="", y="")


SSM_Chroma + theme(axis.text.x= element_text(face="plain" ,angle=45, hjust=1))

# Euclidean as distance: You can see the big change at 60 seconds very well.

Lacrimosa_Timbre <-
    get_tidy_audio_analysis('1UvaZaHkh3D9AkmBrrnbFg') %>%
    compmus_align(bars,segments) %>% # aligns everything at a higher lvl of the spotify fpi, he first argument of compmus align can be bars, beats or section.
    select(bars) %>% unnest(bars) %>%
    mutate(
        pitches = # gives pitch information
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm ='euclidean' )) %>% # You can change the method to rms, mean, max and so on, see table (method summary). You can also change the norm again, see table
    mutate(
        timbre = #gives timbre information
            map(segments,
                compmus_summarise, timbre,
                method = 'rms')) # You can change the method again.

Lacrimosa_Timbre %>%  # Timbre self similairity matrix
    compmus_self_similarity(timbre, 'euclidean') %>%  # Here you can change the secon argument again, meaning you change the distance.
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'B', guide = 'none') +
    theme_classic() +
    labs(title="Lacrimosa Timbre SSM Using Euclidean Distance",x = 'Time (s)', y = 'Time (s)')

Brainstorm_Timbre <-
    get_tidy_audio_analysis('4GdOWNJzpTWoKdA4LEbXDa') %>%
    compmus_align(bars,segments) %>% # aligns everything at a higher lvl of the spotify fpi, he first argument of compmus align can be bars, beats or section.
    select(bars) %>% unnest(bars) %>%
    mutate(
        pitches = # gives pitch information
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm ='euclidean' )) %>% # You can change the method to rms, mean, max and so on, see table (method summary). You can also change the norm again, see table
    mutate(
        timbre = #gives timbre information
            map(segments,
                compmus_summarise, timbre,
                method = 'rms')) # You can change the method again.


# Cosine as distance: You can see small differences better.
Brainstorm_Timbre %>%  # Timbre self similairity matrix
    compmus_self_similarity(timbre, 'euclidean') %>%  # Here you can change the secon argument again, meaning you change the distance.
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'B', guide = 'none') +
    theme_classic() +
    labs(title="Brainstorm Timbre SSM Using Euclidean Distance",x = 'Time (s)', y = 'Time (s)')+
  scale_x_continuous(
    breaks = c(0,60,100,130,190,244,305), minor_breaks=NULL) +
  scale_y_continuous(
    breaks = c(0,60,100,130,190,244,305),minor_breaks=NULL)



```

***

__Lacrimosa__

The timbre and chroma SSM's show slight differences, but in general are very similair. They both show a section until 25 seconds, representing the first two measures. Then a straight line can be seen representing the vocal buildup starting at 25 seconds. At 50 seconds a new block starts again. The plots are a bit vague (didn't change when using different distances), probably indicating that due to the polynomials of the vocals this song is difficult to analyze.

<html>
<audio controls>
  <source src="Lacrimosa_Alex.mp3" type="audio/mpeg">
</audio>
</html>

__Brainstorm__

On the x-axis and the y-axis we can see the names describing the __start__ of a new music block. For instance, the song starts with a slow buildup at 0 sec untill around 60 sec (1:00), here a new block starts with some heavy bass, then at 100 sec (1:40) the block is still the same as before, but the high heads kick in. At 130 sec (2:10) the Piano block starts, where at 190 sec (3:08) the Bass block with high heads is repeated. Then at 244 sec (4:05) the Piano block is repeated and at 305 sec (5:02) the autro block starts. Listen to the song to find out!

<html>
<audio controls>
  <source src="Brainstorm Special Request.mp3" type="audio/mpeg">
</audio>
</html>

If we look at the Timbre SSM we see some smaller patterns. As the song starts with some bass, high heads and some low vocals all of a sudden at 60 seconds a lot of low bass is added and this is easy to see by the yellow line, showing up clearer for timbre than chroma. Also we see a change at 244 seconds (4:02-4:05). This is because a weird vocal sample that is only played here in the song.

### **Interactive Timbre SSM shows all the changes of Brainstorm**

```{r chunk8}


brain_active=Brainstorm_Timbre %>%  # Timbre self similairity matrix
    compmus_self_similarity(timbre, 'cosine') %>%  # Here you can change the secon argument again, meaning you change the distance.
    ggplot(
        aes(
            x = xstart + xduration / 2,
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'B', guide = 'none') +
    theme_classic() +
    labs(title="Timbre SSM Using Cosine Distance",x = 'Time (s)', y = 'Time (s)')+
  scale_x_continuous(
    breaks = c(0,60,100,130,190,244,305), minor_breaks=NULL) +
  scale_y_continuous(
    breaks = c(0,60,100,130,190,244,305),minor_breaks=NULL)

ggplotly(brain_active)

```

***

When using Euclidean as distance for the timbre SSM, some structure is lost, however some very big changes show better, like the one at 60 seconds. Therefore an interactive timbre plot using Cosine distance is shown here displaying smaller changes.

Take a look at the file again to check the specific moments.

- Slow buildup 0 sec
- Bass block 60 sec (1:00)
- Bass block + High Heads 100 sec (1:40)
- Piano block 130 sec (2:10)
- Bass block + High Heads 190 sec (3:08)
- Piano block 244 sec (4:05), where the one weird vocal sentence starts at 4:03
- Autro block 305 sec (5:02)

<html>
<audio controls>
  <source src="Brainstorm Special Request.mp3" type="audio/mpeg">
</audio>
</html>



### **Novelty functions and Tempograms for Lacrimosa & Brainstorm. Can the beats be derived?**{data-commentary-width=298}

```{r}

# Novelty functions
brain <-
    get_tidy_audio_analysis("4GdOWNJzpTWoKdA4LEbXDa") %>%
    select(segments) %>% unnest(segments)

lacrimosa_novelty <-
    get_tidy_audio_analysis("1UvaZaHkh3D9AkmBrrnbFg") %>%
    select(segments) %>% unnest(segments)

lacrimosa_novelty %>%
    mutate(loudness_max_time = start + loudness_max_time) %>%
    arrange(loudness_max_time) %>%
    mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
    ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
    geom_line() +
    xlim(0, 30) + # You can change the x limit, to change the section of the song where you want to look at.
    theme_minimal() +
    labs(x = 'Time (s)', y = 'Novelty', title="Lacrimosa Novelty Function Until 30s")

brain %>%
    mutate(loudness_max_time = start + loudness_max_time) %>%
    arrange(loudness_max_time) %>%
    mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
    ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
    geom_line() +
    xlim(0, 60) + # You can change the x limit, to change the section of the song where you want to look at.
    theme_minimal() +
    labs(x = 'Time (s)', y = 'Novelty', title="Brainstorm Novelty Function Until 60s")

#Tempograms
brain <- get_tidy_audio_analysis("4GdOWNJzpTWoKdA4LEbXDa")
lacrimosa_novelty <- get_tidy_audio_analysis("1UvaZaHkh3D9AkmBrrnbFg")

lacrimosa_novelty %>% # The BM it shows us is not correct at all, it gives bout 520, but its not. THe actual bpm is around 132.
    tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>% # window s
    ggplot(aes(x = time, y = bpm, fill = power)) +
    geom_raster() +
    scale_fill_viridis_c(guide = 'none') +
    labs(x = 'Time (s)', y = 'Tempo (BPM)',title="Lacrimosa Fourier Tempogram") +
    theme_classic()

brain %>% # The BM it shows us is not correct at all, it gives bout 520, but its not. THe actual bpm is around 132.
    tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>% # window s
    ggplot(aes(x = time, y = bpm, fill = power)) +
    geom_raster() +
    scale_fill_viridis_c(guide = 'none') +
    labs(x = 'Time (s)', y = 'Tempo (BPM)',title="Brainstorm Fourier Tempogram") +
    theme_classic()

lacrimosa_novelty %>%  # Here it does give the correct bpm of round 132.
    tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
    ggplot(aes(x = time, y = bpm, fill = power)) +
    geom_raster() +
    scale_fill_viridis_c(guide = 'none') +
    labs(x = 'Time (s)', y = 'Tempo (BPM)',title="Lacrimosa Cyclic Tempogram") +
    theme_classic()


brain %>%  # Here it does give the correct bpm of round 132.
    tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
    ggplot(aes(x = time, y = bpm, fill = power)) +
    geom_raster() +
    scale_fill_viridis_c(guide = 'none') +
    labs(x = 'Time (s)', y = 'Tempo (BPM)',title="Brainstorm Cyclic Tempogram") +
    theme_classic()



```

***

__Lacrimosa__:

- __Novelty Function__: The novelty plot shows the first 30s, which start with 10s of only violin and then the vocals come in. We can see that it's not very consistent.

- __Tempogram__: As expected from the novelty function, we can see that for both the Fourier Tempogram and the Cyclic Tempogram the algorithm has absolutely no idea what's going on. Lacrimosa's bpm is quite slow with a BPM of 95 (Alex's version, from Lisa Beckley). The Fourier Tempogram shows us absolutely nothing, and looking at the Cyclic Tempogram it looks like it's actually suggesting higer BPM's of around 150 BPM, however we know that this is false.

__Brainstorm__:

- __Novelty Function__: The novelty plot seems to work well and shows that there is a very regular beat. At 30 seconds, the bass of the beat becomes even louder and becomes more obvious which we can see in the plot. There are also some high heads, which are the smaller peaks we see in the plot.

- __Tempogram__:
We see two very interesting things here. The Fourier analysis does not work, as it's suggesting a tempo of around 520 while we know that the tempo of this song is around 132. This must be because of the tempo harmonics. We can see that the Cyclic tempogram is showing us the correct resultss, as it works around the harmmonics and shows us the true tempo of around 132. It's not very surprising that the tempogram works so wel, as this song has a very obvious beat throughout the whole song.


### **The Transformation of Discover Weekly has occured!** {data-commentary-width=290}

```{r chunk12, fig.height=10, fig.width=6}
library(lubridate)
discover_weekly_archive$week=isoweek(discover_weekly_archive$added_at)

 # discover_weekly_archive=cbind(discover_weekly_archive, week): WAS NIET NODIG

# Make a new data.frame of the archive with only important features you want to look at.
discover_weekly_archive_features=discover_weekly_archive[c(6,7,13,16,62)]


# We give this new table a new: means_all

means_all=aggregate(x=discover_weekly_archive_features, by=list(discover_weekly_archive_features$week), FUN =mean)

median_all=aggregate(x=discover_weekly_archive_features, by=list(discover_weekly_archive_features$week), FUN =median)


# without tempo
means_all_2=means_all[-5]

# Dividning tempo by 100
means_all_3=means_all
means_all_3$tempo=means_all_3$tempo/100

median_all$tempo=median_all$tempo/100



# Orignial
features_longer=pivot_longer(means_all,c(danceability,instrumentalness,tempo,energy), names_to = "feature")
median_longer=pivot_longer(median_all,c(danceability,instrumentalness,tempo,energy), names_to = "feature")


# Without tempo
features_longer_2=pivot_longer(means_all,c(danceability,instrumentalness,energy), names_to = "feature")


# Tempo/100
features_longer_3=pivot_longer(means_all_3,c(danceability,instrumentalness,energy, tempo), names_to = "feature")

# Make week a chracter
features_longer$week=as.character(features_longer$week)
features_longer_2$week=as.character(features_longer_2$week)
features_longer_3$week=as.character(features_longer_3$week)
features_longer_3$value=round(features_longer_3$value,2)

features_longer_3$week <- factor(features_longer_3$week, levels = c("6","7","8","9","10","11", "12", "13"), labels = c("Week 1","Week 2","Week 3","Week 4", "Week 5", "Week 6", "Week 7", "Week 8"))


# For the median
median_longer$week=as.character(median_longer$week)
median_longer$value=round(median_longer$value,2)
median_longer$week <- factor(median_longer$week, levels = c("6","7","8","9","10","11", "12", "13"), labels = c("Week 1","Week 2","Week 3","Week 4", "Week 5", "Week 6", "Week7", "Week 8"))
require(dplyr)
library(CGPfunctions)


# Lijnen onderscheiden zich niet omdat tempo te hoog ligt
# Plot voor als je tempo erin wil geeft leijke plot: newggslopegraph(dataframe=features_longer, Times=week, Measurement = value, Grouping = feature)

# Tempo eruit getyft
# Plot voor als je tempo eruit wilt: newggslopegraph(dataframe=features_longer_2, Times=week, Measurement = value, Grouping = feature)


# Tempo/100 for the MEAN
graph=newggslopegraph(dataframe=features_longer_3, Times=week, Measurement = value, Grouping = feature, Title= "Mean Changes per Week", SubTitle = NULL, WiderLabels = TRUE, YTextSize = 4, DataTextSize = 4, DataLabelPadding = 0.0001, LineThickness = 2)+
  labs(title="Audio Features",
       subtitle="Change of Means",
       x = NULL) +
  theme_minimal()



graph <- graph + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))

graph

# tempo/100 for the MEDIAN
# newggslopegraph(dataframe=median_longer, Times=week, Measurement = value, Grouping = feature, Title= "Median Changes per Week", SubTitle = NULL, WiderLabels = TRUE, YTextSize = 4, DataTextSize = 4, DataLabelPadding = 0.0001, LineThickness = 2)

graph2=newggslopegraph(dataframe=median_longer, Times=week, Measurement = value, Grouping = feature, Title= "Mean Changes per Week", SubTitle = NULL, WiderLabels = TRUE, YTextSize = 4, DataTextSize = 4, DataLabelPadding = 0.0001, LineThickness = 2)+
  labs(title="Audio Features",
       subtitle="Change of Medians",
       x = NULL) +
  theme_minimal()


graph2 <- graph2 + theme(legend.position = "none", plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))

graph2

```

***

These Plots show the changes over the 8 weeks for each feature. The left plot shows the means and the right shows the medians of the values. They both show similair results. The tempo values are devided by 100, else they wouldn't fit on the plot. Thus tempo= 1.16 equals tempo=116.

The first thing to notice when looking at the means is the big increase in instrumentalness for week one, which than starts to drop continuously untill in week 6 it rises all of a sudden, to drop once again in week 7 and 8. In general, tempo and dancebility seem to steadily, but slowly go up. What can be seen is that for all variables something weird is happening at week 6. Now what happened here was actually a big accident, but turned out to be very usefull. A friend of mine put on an artist named __khruangbin__,

<html>
<audio controls>
  <source src="Khruangbin.mp3" type="audio/mpeg">
</audio>
</html>

which is a very relaxed kind of chill out music. I had forgotten, that my spotify wasn't on the function private session (which allows you to listen to music without the spotify weekly algorithm listening in on you), thus my discover weekly was listening to my listening behavior. After 20 minutes I realised this and quickly changed it to a private session. However, it seems ike discover weekly quickly picked up on my changing behavior. And this is what we see for week 6.

It was hypothesized that all of the four features would go up in value. We can see that all the means indeed did go up! Also looking at the median values, these all went up. What is quite noticable is that the tempo and danceability went up quite a bit, but the energy didn't change that much. Which is weird, as I though these variables were highly correlated. If it hadn't been for my mistake in week 6, the changes at week 8 might have been even bigger.

### **Distributions, Means and Median changes per week. Big changes for Danceability and Tempo!**


```{r chunk13, fig.width=9, fig.height=6.5}
week_numbers=c(1,2,3,4,5,6,7,8)

plot1=ggplot(means_all, aes(week, danceability, col=instrumentalness, size=energy))+
  geom_point()+
  labs(title='Mean Changes per Week',
    x = "Week",
    y = "Danceability",
    colour = "Instrumentalness",
    size="Energy")  +
    scale_x_continuous(          # Fine-tune the x axis.
    breaks = c(6,7,8,9,10,11,12,13),  # Use grid-lines for quadrants only.
    minor_breaks = NULL,      # Remove 'minor' grid-lines.
    labels=week_numbers
  )+
    lims(size=c(0.55,0.75))+
   geom_smooth(show.legend = FALSE, se=FALSE)+
  scale_color_viridis( option = "D")


week_numbers=c(1,2,3,4,5,6,7,8)

plot2=ggplot(median_all, aes(week, danceability, col=instrumentalness, size=energy))+
  geom_point()+
  labs(title='Median Changes per Week',
    x = "Week",
    y = "Danceability",
    colour = "Instrumentalness",
    size="Energy")  +
    scale_x_continuous(          # Fine-tune the x axis.
    breaks = c(6,7,8,9,10,11,12,13),  # Use grid-lines for quadrants only.
    minor_breaks = NULL,      # Remove 'minor' grid-lines.
    labels=week_numbers
  )+
  lims(size=c(0.55,0.75))+
  geom_smooth(show.legend = FALSE, se=FALSE) +
  scale_color_viridis( option = "D")


plot3=ggplot(discover_weekly1, aes(energy, danceability, col=instrumentalness, size=tempo))+
  geom_point()+
  labs(title='Discover Weekly 1',
    x = "Energy",
    y = "Danceability",
    colour = "Instrumentalness",
    size="Tempo")+
  scale_color_viridis( option = "D")



plot4=ggplot(discover_weekly8, aes(energy, danceability, col=instrumentalness, size=tempo))+
  geom_point()+
  labs(title='Discover Weekly 8',
    x = "Energy",
    y = "Danceability",
    colour = "Instrumentalness",
    size="Tempo")  +
    lims(size=c(100,175))+
  scale_color_viridis( option = "D")

gridExtra::grid.arrange(plot1, plot2, plot3, plot4, ncol = 2, nrow = 2)

```

***

As an addition to the previous plot, the plots at the top show the mean changes and the median changes per week. Showing the Energy in size, the instrumentalness in color and the Danceability on the y-axis. Where the weeks are given on the x-axis. For both plots we can see that all features go up, and the little accident happening at week 6.

The bottom two plots respresent week 1 and week 8 of discover weekly, showing the distribution of the absolute values for all 4 features. We can clearly see that the danceability of the songs is quite high and less spread than in week 1. The spread of the energy doesn't show very different from this plot compared to week 1. There seem to be more yellow dots, meaning a higher instrumentalness. Also in general, the dots are larger, meaning a higher tempo.

### **Classification with  Multinomial Regression. What features are important for what playlist?** {data-commentary-width=305}


```{r}

# My Spotify Favorites
favorites=
  get_playlist_audio_features("Tosca Beijaert","16OAuKPZYr8YM4a9n1V6kf")  %>%
  slice(1:30) %>%
  add_audio_analysis

# Because there were local files in the list, spotify added extra columns, which i removed as the other
# playlists don't have these comments, so it will be useless for compariosn.
favorites=favorites[-c(59:63)]

# We also have to remove the local files, as i cannot  compare them as there is no analysis for these tracks.
favorites=subset(favorites, track.is_local==FALSE) # we delete the local files

alex=
  get_playlist_audio_features("Alexander Keijser","59c8tug3WdwODj6gV0ierq") %>%
  slice(1:30) %>%
  add_audio_analysis

discover_weekly8=
  get_playlist_audio_features("Tosca Beijaert","4GhJfgljCrnaIbJ30qIabQ") %>%
  slice(1:30) %>%
  add_audio_analysis


Playlists <-
    favorites %>% mutate(playlist = "My Favorites") %>%
    bind_rows(
        alex %>% mutate(playlist = "Alex's Favorites"),
        discover_weekly8 %>% mutate(playlist = "Discover_weekly8")) %>%
    mutate(playlist = factor(playlist)) %>%
    mutate(
        segments =
            map2(segments, key, compmus_c_transpose)) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>%
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>%
    mutate_at(vars(pitches, timbre), map, bind_rows) %>%
    unnest(cols = c(pitches, timbre))

### Pre-processing


Playlists_class <-
    recipe(playlist ~ # You probably only need to play this playlist, so the thing you want to predict.
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = Playlists) %>%
    step_center(all_predictors()) %>% # This one works better most of the times, if not try the step range.
    step_scale(all_predictors()) %>% # Change the scale to z-scores
    # step_range(all_predictors()) %>%
    prep(Playlists) %>%
    juice

### Cross-Validation

# The `vfold_cv` function sets up cross-validation. We will use 5-fold cross-validation here in the interest of speed, but 10-fold cross-validation is more typical.


Playlists_cv <- Playlists_class %>% vfold_cv(5) # Use either 5 or 10: It splits your data in e.g. 5 parts. And does a k-fold crossvalidation


### Classification Algorithms

#### $k$-Nearest Neighbour

# A $k$-nearest neighbour classifier often works just fine with only one neighbour. It is very sensitive to the choice of features, however. Let's check the performance as a baseline and come back to it later.
#
#  Just run this code if you want to use k nearest neighbour.

Playlists_knn <-
    nearest_neighbor(mode = 'classification', neighbors = 1) %>%
    set_engine('kknn')

Playlists_predict_knn <- function(split)
    fit(Playlists_knn, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))


# These matrices `autoplot` in two forms.
Playlists_multinom <-
    multinom_reg(mode = 'classification', penalty = 0.1) %>%
    set_engine('glmnet')

Playlists_predict_multinom <- function(split)
    fit(Playlists_multinom, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Accuracy for k-nearest neighbor

# Playlists_cv %>%
#     mutate(pred = map(splits, Playlists_predict_knn)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

# accuracy for multinom

# Playlists_cv %>%
#     mutate(pred = map(splits, Playlists_predict_multinom)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)


# Accuracy for decision trees
Playlists_tree <-
    decision_tree(mode = 'classification') %>%
    set_engine('C5.0')
predict_tree <- function(split)
    fit(Playlists_tree, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Playlists_cv %>%
#     mutate(pred = map(splits, predict_tree)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

# Accuracy for random forest

# These are the best! Will give you the best results.
Playlists_forest <-
    rand_forest(mode = 'classification') %>%
    set_engine('randomForest')
predict_forest <- function(split)
    fit(Playlists_forest, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
#
# Playlists_cv %>%
#     mutate(pred = map(splits, predict_forest)) %>%
#     unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

# Reduced k nearest-neighbour

predict_knn_reduced <- function(split)
    fit(
        Playlists_knn,
        playlist ~ danceability + c04 + duration + tempo + loudness ,  # Here he used less features, and gets better results.
        data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Playlists_cv %>%
#     mutate(pred = map(splits, predict_knn_reduced)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)


Playlists_cv %>%
    mutate(pred = map(splits, Playlists_predict_multinom)) %>% unnest(pred) %>%
    conf_mat(truth = playlist, estimate = .pred_class) %>%
    autoplot(type = 'mosaic')

Playlists_cv %>%
    mutate(pred = map(splits, Playlists_predict_multinom)) %>% unnest(pred) %>%
    conf_mat(truth = playlist, estimate = .pred_class) %>%
    autoplot(type = 'heatmap')

# Multinom important features

Playlists_class %>% # For alex: D#/Eb, c05, A#|Bb. for discover weekly 7:speechiness, instrumentalness, duration, for favorites: danceability, C
    fit(Playlists_multinom, playlist ~ ., data = .) %>%
    pluck('fit') %>%
    coef(s = 0)

```

***

Different prediction algorithms were tested to find the algorithm with the highest accuracy. The following accuracies were found out:

- 1. K-nearest neighbour: 0.533
- 2. Multinomial regression: 0.611
- 3. Decision Trees: 0.605
- 4. Random Forest: 0.700
- 5. K-nearest neighbour using Random forest selected features: 0.591

The accuracy showed that k-nearest neighbour didn't do that well. All the others perform about the same, with Random forest doing slightly better. Also we saw that k-nearest neighbour improved after only the important features according to the random forest were used being: Danceability + c04 + duration + tempo + loudness

On the left we see two plots showing the confusion matrix for the Multinomial Regression, as we will later use the most meaningfull feaatures according to the multinomial regression to look at clusters in the Discover Weekly 8 playlist. This plot clearly show that it's best at correctly classifying songs from my favorites. 

Underneath these plots we can see a table showing the features that contribute the most according to multinomial regression. Where very high or very low values contribute the most to making the correct predictions.

- We can see that for Alexâ€™s favorites: Instrumentalness, C, and B are important for prediction.
- We can see that for Discover weekly 8: Accousticness, E and Valence were important for prediction.
- We can see that for My favorites: Danceability, c05 and G#|Ab are important for prediction.

In the Additional Results IV, the results of the various analyses can be found. Showing the confusion matrixes and the accuracy tables. From these analysis it was found out that every algorithm is the best at correctly predicting songs that belong to my favorites. Why this is the case, I'm not sure.


### **Using Multinomial selected features shows us Clusters in Discover Weekly 8!** {data-commentary-width=711}


```{r}

Discoverweekly8 <-
    get_playlist_audio_features("Tosca Beijaert","4GhJfgljCrnaIbJ30qIabQ") %>%
    add_audio_analysis %>%
    mutate(
        segments =
            map2(segments, key, compmus_c_transpose)) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>%
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>%
    mutate_at(vars(pitches, timbre), map, bind_rows) %>%
    unnest(cols = c(pitches, timbre))


Discoverweekly8_multinom_juice <-
    recipe(track.name ~
               # danceability +
               # energy +
               loudness +
               # speechiness +
               acousticness +
               # instrumentalness +
               # liveness +
               valence +
               # tempo +
               # duration +
               # C + `C#|Db` + D + `D#|Eb` +
                E +
             #`F` + `F#|Gb` + G +
               # `G#|Ab` + A + `A#|Bb` + B +
               # c01 +
             # c02 + c03 +
              # c04+
           # + c05 + c06 +
           #     c07 + c08 +
             c09 ,
           # + c10 + c11 + c12,
           data = Discoverweekly8) %>%
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>%
    prep(Discoverweekly8 %>% mutate(track.name = str_trunc(track.name, 20))) %>%
    juice %>%
    column_to_rownames('track.name')

Discoverweekly8_multinom_dist<- dist(Discoverweekly8_multinom_juice, method = 'euclidean')


dev.new()
heatmaply(
    Discoverweekly8_multinom_juice,
    main = "Discover Weekly 8 Clusters Using Selected Features",
    # hclustfun = hclust,
    hclustfun = protoclust,
    # Comment out the hclust_method line when using protoclust.
    # hclust_method = 'average',
    dist_method = 'euclidean'
    )%>%
  layout(autosize = F, width = 800, height = 500)

```

***

```{r dendogram,fig.height=4, fig.width=8}

protoclust(Discoverweekly8_multinom_dist) %>% dendro_data %>% ggdendrogram # using all features
```

In the previous section it was found out using a multinomial regression which features contribute the most for which playlist. For our discover weekly 8 playlist the top features were: Accousticnesss (-30), E (22), Loudness (-18), Valence (-17) and c09 (-15). When looking at all features there were no clusters to be found in the heatmap nor did the denodogram make any sense, thus these plots will not be shown nor looked at. Instead, we will use only the important features that we found in the multinomial regression for finding clusters.


Looking at the __Dendogram__, we see a small amound of clusters. There are a few things to notice:

- We can see one song all the way on the left, Milles Away, which is a very slow jazzy song. My guess is that it's looking at the instrumentalness here.

- Two other songs that are at the end of a cluster together are: Kids Play & Cola bottle baby. These two songs are both quite funky and sound very much alike. Which feature it's using I'm not sure. The heatmaps will give us more answers.

Looking at the __Heatmap__, we can notice some thing:

- We see a very clear cluster for accousticness, which makes sense as this was our strongest predictor accoridng to GLM.

- We can also see very clearly that one song we noticed in the dendogram, Miles Away, is all on it's own, having a high value for accousticness (yellow).

- The other two songs we looked at in the dendogram, Kids Play & Cola bottle baby, can also be found quite easily. When looking at valence, we see that they both have a value of around 2.

- We can also see a cluster for low values of c09 at the top left, which is some kind of timbre component. When listening to these songs, Parley, Carino, Knuf and Street life, I couldn't figure out what would make them different from the other songs. However we can also see this cluster in the dendogram.

- And we notice that the song Luechtoorn, which is also on it's own in the dendogram, has quite a high value for E, which seperates it from the other songs.

### **ADDITIONAL RESULTS:** The following appendixes show various analyses of the 3 Playlists and theLacrimosa VS Brainstorm topic (If you have time, take a look) **I: The Key of our Playlists** 

```{r chunk2, fig.width=10, fig.height=7}

# We make the Key histograms
playlists_end=
  alex %>% mutate(playlist = "Alex") %>%
  bind_rows(favorites %>% mutate(playlist = "Favorites")) %>%
  bind_rows(discover_weekly1%>% mutate(playlist = "Discover Weekly 1"))

key_x=c("C","C#|Db", "D","D#|Eb" ,"E", "F", "F#|Gb", "G", "G#|Ab", "A", "A#|Bb", "B" ) # Vector with label for the x-axis

key_per_playlist=
  playlists_end %>%
  ggplot(aes(x = key, col=playlist)) +
  geom_bar() +
  facet_wrap(~ playlist, scales="free_y")+
  labs(color='Playlist', title='Key per Playlist') +
  xlab('Key') +
  ylab("Count")+
  scale_x_continuous(
    labels= key_x,
    breaks = c(0,1,2,3,4,5,6,7,8,9,10,11)         # Fine-tune the x axis.
     # Use grid-lines for quadrants only.      # Remove 'minor' grid-lines.
  )

key_per_playlist + theme(axis.text.x= element_text(face="plain" ,angle=45, hjust=1))




```

***

Here we see the distributions of the keys per playlist at the baseline. You can see that for every playlist, a lot of the songs are in the key of C. However, there are also a lot for C#|Db, G & A. Alex told me that he really like the key of Db, giving us an explanation for why that occurs so often in his playlist. We see that for discover weekly 1, G occurs most often. This makes sense as the key of G is quite popular and spotify weekly in general recommends songs that are popular. I do not have an explanation for my Favorites, I don't have a particular preference. Which you can see a little bit, as multiple keys occur with a high frequency, e.g. C, D, G and A.

### **II: Chroma, Timbre & Key plots for Lacrimosa & Brainstorm**{data-commentary-width=290}

```{r chunk4}

circshift <- function(v, n) {if (n == 0) v else c(tail(v, n), head(v, -n))}

    # C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
    c(1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
    c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
    c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
    tribble(
        ~name  , ~template,
        'Gb:7'  , circshift(seventh_chord,  6),
        'Gb:maj', circshift(major_chord,    6),
        'Bb:min', circshift(minor_chord,   10),
        'Db:maj', circshift(major_chord,    1),
        'F:min' , circshift(minor_chord,    5),
        'Ab:7'  , circshift(seventh_chord,  8),
        'Ab:maj', circshift(major_chord,    8),
        'C:min' , circshift(minor_chord,    0),
        'Eb:7'  , circshift(seventh_chord,  3),
        'Eb:maj', circshift(major_chord,    3),
        'G:min' , circshift(minor_chord,    7),
        'Bb:7'  , circshift(seventh_chord, 10),
        'Bb:maj', circshift(major_chord,   10),
        'D:min' , circshift(minor_chord,    2),
        'F:7'   , circshift(seventh_chord,  5),
        'F:maj' , circshift(major_chord,    5),
        'A:min' , circshift(minor_chord,    9),
        'C:7'   , circshift(seventh_chord,  0),
        'C:maj' , circshift(major_chord,    0),
        'E:min' , circshift(minor_chord,    4),
        'G:7'   , circshift(seventh_chord,  7),
        'G:maj' , circshift(major_chord,    7),
        'B:min' , circshift(minor_chord,   11),
        'D:7'   , circshift(seventh_chord,  2),
        'D:maj' , circshift(major_chord,    2),
        'F#:min', circshift(minor_chord,    6),
        'A:7'   , circshift(seventh_chord,  9),
        'A:maj' , circshift(major_chord,    9),
        'C#:min', circshift(minor_chord,    1),
        'E:7'   , circshift(seventh_chord,  4),
        'E:maj' , circshift(major_chord,    4),
        'G#:min', circshift(minor_chord,    8),
        'B:7'   , circshift(seventh_chord, 11),
        'B:maj' , circshift(major_chord,   11),
        'D#:min', circshift(minor_chord,    3))

key_templates <-
    tribble(
        ~name    , ~template,
        'Gb:maj', circshift(major_key,  6),
        'Bb:min', circshift(minor_key, 10),
        'Db:maj', circshift(major_key,  1),
        'F:min' , circshift(minor_key,  5),
        'Ab:maj', circshift(major_key,  8),
        'C:min' , circshift(minor_key,  0),
        'Eb:maj', circshift(major_key,  3),
        'G:min' , circshift(minor_key,  7),
        'Bb:maj', circshift(major_key, 10),
        'D:min' , circshift(minor_key,  2),
        'F:maj' , circshift(major_key,  5),
        'A:min' , circshift(minor_key,  9),
        'C:maj' , circshift(major_key,  0),
        'E:min' , circshift(minor_key,  4),
        'G:maj' , circshift(major_key,  7),
        'B:min' , circshift(minor_key, 11),
        'D:maj' , circshift(major_key,  2),
        'F#:min', circshift(minor_key,  6),
        'A:maj' , circshift(major_key,  9),
        'C#:min', circshift(minor_key,  1),
        'E:maj' , circshift(major_key,  4),
        'G#:min', circshift(minor_key,  8),
        'B:maj' , circshift(major_key, 11),
        'D#:min', circshift(minor_key,  3))

Lacrimosa_Chroma =
    get_tidy_audio_analysis("1UvaZaHkh3D9AkmBrrnbFg") %>%
    select(segments) %>% unnest(segments) %>%
    select(start, duration, pitches)

lacrimosa2 =
    get_tidy_audio_analysis("3oHSL6pt9LpNrQZuQGu9wL") %>%
    select(segments) %>% unnest(segments) %>%
    select(start, duration, pitches)

Lacrimosa_Chroma %>%
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% # Change Euclidean to something you want: manhattan, euclidean or chebyshev
    compmus_gather_chroma %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = pitch_class,
            fill = value)) +
  scale_fill_viridis_c(option = 'C', guide = ) +
    geom_tile() +
    labs(title= "Chroma-plot: Lacrimosa by Mozart",x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    theme_classic()


Brainstorm_Chroma=
    get_tidy_audio_analysis("4GdOWNJzpTWoKdA4LEbXDa") %>%
    select(segments) %>% unnest(segments) %>%
    select(start, duration, pitches)

# Chroma using Euclidean: Werkt
Brainstorm_Chroma%>%
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% # Change Euclidean to something you want: manhattan, euclidean or chebyshev
    compmus_gather_chroma %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = pitch_class,
            fill = value)) +
    geom_tile() +
    labs(title= "Chroma-plot: Brainstorm by Special Request",x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'C') + # You can change this color, this one is very nice.
    theme_classic()

Lacrimosa_Timbre <-
    get_tidy_audio_analysis('1UvaZaHkh3D9AkmBrrnbFg') %>%
    compmus_align(bars,segments) %>% # aligns everything at a higher lvl of the spotify fpi, he first argument of compmus align can be bars, beats or section.
    select(bars) %>% unnest(bars) %>%
    mutate(
        pitches = # gives pitch information
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm ='euclidean' )) %>% # You can change the method to rms, mean, max and so on, see table (method summary). You can also change the norm again, see table
    mutate(
        timbre = #gives timbre information
            map(segments,
                compmus_summarise, timbre,
                method = 'rms')) # You can change the method again.

Lacrimosa_Timbre %>%
    compmus_gather_timbre %>% # You can leave this alone, you don't need to change anything here.
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = basis,
            fill = value)) +
    geom_tile() +
    labs(title="Timbre-plot: Lacrimosa by Mozart",x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'A') + # You can change this color, this one is very nice.
    theme_classic()

# lacrimosa2 %>%
#     mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% # Change Euclidean to something you want: manhattan, euclidean or chebyshev
#     compmus_gather_chroma %>%
#     ggplot(
#         aes(
#             x = start + duration / 2,
#             width = duration,
#             y = pitch_class,
#             fill = value)) +
#     scale_fill_viridis_c(option = 'C', guide = ) +
#     geom_tile() +
#     labs(title= "Chromaplot: My Lacrimosa",x = 'Time (s)', y = NULL, fill = 'Magnitude') +
#     theme_classic()




Brainstorm_Timbre <-
    get_tidy_audio_analysis('4GdOWNJzpTWoKdA4LEbXDa') %>%
    compmus_align(bars,segments) %>% # aligns everything at a higher lvl of the spotify fpi, he first argument of compmus align can be bars, beats or section.
    select(bars) %>% unnest(bars) %>%
    mutate(
        pitches = # gives pitch information
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm ='euclidean' )) %>% # You can change the method to rms, mean, max and so on, see table (method summary). You can also change the norm again, see table
    mutate(
        timbre = #gives timbre information
            map(segments,
                compmus_summarise, timbre,
                method = 'rms')) # You can change the method again.

Brainstorm_Timbre %>%
    compmus_gather_timbre %>% # You can leave this alone, you don't need to change anything here.
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = basis,
            fill = value)) +
    geom_tile() +
    labs(title="Timbre-plot: Brainstorm by Special Request Chroma",x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'A') + # You can change this color, this one is very nice.
    theme_classic()

lacrimosa_key <-
    get_tidy_audio_analysis('1UvaZaHkh3D9AkmBrrnbFg') %>%
    compmus_align(sections, segments) %>%
    select(sections) %>% unnest(sections) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'))

# lacrimosa_key2 <-
#     get_tidy_audio_analysis('3oHSL6pt9LpNrQZuQGu9wL') %>%
#     compmus_align(sections, segments) %>%
#     select(sections) %>% unnest(sections) %>%
#     mutate(
#         pitches =
#             map(segments,
#                 compmus_summarise, pitches,
#                 method = 'mean', norm = 'manhattan'))


lacrimosa_key %>%
    compmus_match_pitch_template(key_templates, 'cosine', 'euclidean') %>%
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'D') +
    labs(title= "Key-Plot: Lacrimosa by Mozart",x = 'Time (s)', y = NULL, fill = 'Magnitude')+
    theme_minimal() +
    labs(x = 'Time (s)', y = '')

# lacrimosa_key2 %>%
#     compmus_match_pitch_template(key_templates, 'cosine', 'euclidean') %>%
#     ggplot(
#         aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
#     geom_tile() +
#     labs(title= "Key-Plot: My Lacrimosa",x = 'Time (s)', y = NULL, fill = 'Magnitude')+
#     scale_fill_viridis_c(option = 'D') +
#     theme_minimal() +
#     labs(x = 'Time (s)', y = '')
# fjdsajkll


Brainstorm_key <-
    get_tidy_audio_analysis("4GdOWNJzpTWoKdA4LEbXDa") %>%
    compmus_align(sections, segments) %>%
    select(sections) %>% unnest(sections) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'))

Brainstorm_key %>%
    compmus_match_pitch_template(key_templates, 'cosine', 'euclidean') %>%
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'D') +
    labs(title= "Key-plot: Brainstorm by Special Request Chroma",x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'D') + # You can change this color, this one is very nice.
    theme_classic()

```



***


__Lacrimosa__:
Looking at the chroma plot we can sort of see that this song is played in d minor, which consists of D, E, F, G, A, Bb, and C. But the plot is not very easy to read, changing the normalisation or the colors also did not make the chroma plots much clearer. 

<html>
<audio controls>
  <source src="Lacrimosa_Alex.mp3" type="audio/mpeg">
</audio>
</html>

The timbre plot shows a high magnitude for component 2,3 and 5. However they are shown during the whole song, making it difficult to interpret.

The key-plot is not very easy to read. One weird thing would be around 170 seconds (2:50). This moment seems to be around a part where the vocals are a bit softer compared to the rest of the song, and also it's a part that's new, so it hasn't happened before in the song. It's part that first buildsup softly and then goes down again. Basically the key detection has no clue whats going on.

__Brainstorm__
This is an techno-like song which has a lot of changes troughout the song. There is some piano involved and some singing, however not troughout the whole song. Therefore it is difficult to see something out of the chroma plot, as it's not as easy as with classical music.
This can be seen from the chroma plot. On the x-axis we have the time and on the y-axis the chroma. It's hard to conclude anything from this plot at all.

The timbre shows a little bit better what's going on. The song starts with a slow buildup with some high heads and some minimal vocals (Kicking up in the brainstorm), which you can see in the beginning. Then you can see a very big change around 60 seconds, this is where a very heavy bass kicks in. It also shows a single weird moment around 240 seconds, this is because here there is 1 small sample of a vocal which has not been in the song before and is only played here.

The Key-plot shows some very weird high values around 60 seconds, which is where the bass kicks in. Besides that it's hard to conclude anything from this plot


### **III: Looking at important Features using Decision Trees & Random Forests**{data-commentary-width=300}

```{r}


# Random forest plot
Playlists_class %>%
    fit(Playlists_forest, playlist ~ ., data = .) %>%
    pluck('fit') %>%
    randomForest::varImpPlot()


Playlists %>%
    ggplot(aes(x = c04, y = duration, colour = playlist, size = danceability)) +
    geom_point(alpha = 0.8) +
    scale_color_brewer(type = 'qual', palette = 'Accent') +
    labs(
        x = 'Timbre C04',
        y = 'Duration',
        size = 'Danceability',
        colour = 'Playlist',
        title="Important Features According to Random Forests"
    )



# Multinom important features
# 
# Playlists_class %>% # For alex: D#/Eb, c05, A#|Bb. for discover weekly 7:speechiness, instrumentalness, duration, for favorites: danceability, C
#     fit(Playlists_multinom, playlist ~ ., data = .) %>%
#     pluck('fit') %>%
#     coef(s = 0)

Playlists_tree <-
    decision_tree(mode = 'classification') %>%
    set_engine('C5.0')
predict_tree <- function(split)
    fit(Playlists_tree, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Playlists_cv %>%
#     mutate(pred = map(splits, predict_tree)) %>% unnest(pred) %>%
#     conf_mat(truth = playlist, estimate = .pred_class) %>%
#     autoplot(type = 'mosaic') # Change mosaic if you want different plot
#
#
# Playlists_cv %>%
#     mutate(pred = map(splits, predict_tree)) %>% unnest(pred) %>%
#     conf_mat(truth = playlist, estimate = .pred_class) %>%
#     autoplot(type = 'heatmap')


# Decision tree important choices
Playlists_class %>%
    fit(Playlists_tree, playlist ~ ., data = .) %>%
    pluck('fit') %>%
    summary


Playlists_forest <-
    rand_forest(mode = 'classification') %>%
    set_engine('randomForest')
predict_forest <- function(split)
    fit(Playlists_forest, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
# 
# Playlists_cv %>% # The name of your crossvalidation
#     mutate(pred = map(splits, predict_forest)) %>% unnest(pred) %>%
#     conf_mat(truth = playlist, estimate = .pred_class)

# Playlists_cv %>%
#     mutate(pred = map(splits, predict_forest)) %>%
#     unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)
#
# Playlists_cv %>%
#     mutate(pred = map(splits, predict_forest)) %>% unnest(pred) %>%
#     conf_mat(truth = playlist, estimate = .pred_class) %>%
#     autoplot(type = 'mosaic') # Change mosaic if you want different plot


# Playlists_cv %>%
#     mutate(pred = map(splits, predict_forest)) %>% unnest(pred) %>%
#     conf_mat(truth = playlist, estimate = .pred_class) %>%
#     autoplot(type = 'heatmap')



```

***


The first plot shows us the most important factors that we should look at according to the Random Forest algorithm. This shows us that danceability, duration, c04, tempo and loudness are very important. Using these featurest, the second attempemt with k-nearest neigbhours was made in the previous slide.

The second plot shows how these important features are distributed for every playlist. You can see actually see the playlist are a little bit seperated when looking at only these features. E.g. Discover weekly is generally higher on c04 than my favorites are.

The table underneath shows us the choices that the decision tree has made. Their prediction quality is not that good, however we can use them to get a better view at how the decisions for the predictions were made. For instance, we can see that danceability plays a very big role for this prediction. Also, for instance we see that when F <= 1.134423 you have a high chance of belonging to My Favorites.

### **IV: Accuracy of classification with k-Nearest Neighbour, Multinomial Regression, Decision Trees and Random forest:**{data-commentary-width=800}


```{r}

# My Spotify Favorites
favorites=
  get_playlist_audio_features("Tosca Beijaert","16OAuKPZYr8YM4a9n1V6kf")  %>%
  slice(1:30) %>%
  add_audio_analysis

# Because there were local files in the list, spotify added extra columns, which i removed as the other
# playlists don't have these comments, so it will be useless for compariosn.
favorites=favorites[-c(59:63)]

# We also have to remove the local files, as i cannot  compare them as there is no analysis for these tracks.
favorites=subset(favorites, track.is_local==FALSE) # we delete the local files

alex=
  get_playlist_audio_features("Alexander Keijser","59c8tug3WdwODj6gV0ierq") %>%
  slice(1:30) %>%
  add_audio_analysis

discover_weekly8=
  get_playlist_audio_features("Tosca Beijaert","4GhJfgljCrnaIbJ30qIabQ") %>%
  slice(1:30) %>%
  add_audio_analysis


Playlists <-
    favorites %>% mutate(playlist = "My Favorites") %>%
    bind_rows(
        alex %>% mutate(playlist = "Alex's Favorites"),
        discover_weekly8 %>% mutate(playlist = "Discover_weekly8")) %>%
    mutate(playlist = factor(playlist)) %>%
    mutate(
        segments =
            map2(segments, key, compmus_c_transpose)) %>%
    mutate(
        pitches =
            map(segments,
                compmus_summarise, pitches,
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>%
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>%
    mutate_at(vars(pitches, timbre), map, bind_rows) %>%
    unnest(cols = c(pitches, timbre))

### Pre-processing


Playlists_class <-
    recipe(playlist ~ # You probably only need to play this playlist, so the thing you want to predict.
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = Playlists) %>%
    step_center(all_predictors()) %>% # This one works better most of the times, if not try the step range.
    step_scale(all_predictors()) %>% # Change the scale to z-scores
    # step_range(all_predictors()) %>%
    prep(Playlists) %>%
    juice

### Cross-Validation

# The `vfold_cv` function sets up cross-validation. We will use 5-fold cross-validation here in the interest of speed, but 10-fold cross-validation is more typical.


Playlists_cv <- Playlists_class %>% vfold_cv(5) # Use either 5 or 10: It splits your data in e.g. 5 parts. And does a k-fold crossvalidation


### Classification Algorithms

#### $k$-Nearest Neighbour

# A $k$-nearest neighbour classifier often works just fine with only one neighbour. It is very sensitive to the choice of features, however. Let's check the performance as a baseline and come back to it later.
#
#  Just run this code if you want to use k nearest neighbour.

Playlists_knn <-
    nearest_neighbor(mode = 'classification', neighbors = 1) %>%
    set_engine('kknn')

Playlists_predict_knn <- function(split)
    fit(Playlists_knn, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))


# These matrices `autoplot` in two forms.
Playlists_multinom <-
    multinom_reg(mode = 'classification', penalty = 0.1) %>%
    set_engine('glmnet')

Playlists_predict_multinom <- function(split)
    fit(Playlists_multinom, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Accuracy for k-nearest neighbor

# Playlists_cv %>%
#     mutate(pred = map(splits, Playlists_predict_knn)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

# accuracy for multinom

# Playlists_cv %>%
#     mutate(pred = map(splits, Playlists_predict_multinom)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)


# Accuracy for decision trees
Playlists_tree <-
    decision_tree(mode = 'classification') %>%
    set_engine('C5.0')
predict_tree <- function(split)
    fit(Playlists_tree, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Playlists_cv %>%
#     mutate(pred = map(splits, predict_tree)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

# Accuracy for random forest

# These are the best! Will give you the best results.
Playlists_forest <-
    rand_forest(mode = 'classification') %>%
    set_engine('randomForest')
predict_forest <- function(split)
    fit(Playlists_forest, playlist ~ ., data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
#
# Playlists_cv %>%
#     mutate(pred = map(splits, predict_forest)) %>%
#     unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

# Reduced k nearest-neighbour

predict_knn_reduced <- function(split)
    fit(
        Playlists_knn,
        playlist ~ danceability + c04 + duration + tempo + loudness ,  # Here he used less features, and gets better results.
        data = analysis(split)) %>%
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))

# Playlists_cv %>%
#     mutate(pred = map(splits, predict_knn_reduced)) %>% unnest(pred) %>%
#     metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)


Playlists_cv %>%
    mutate(pred = map(splits, Playlists_predict_knn)) %>%
    unnest(pred) %>%
    metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

Playlists_cv %>%
    mutate(pred = map(splits, Playlists_predict_multinom)) %>%
    unnest(pred) %>%
    metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

Playlists_cv %>%
    mutate(pred = map(splits, predict_tree)) %>%
    unnest(pred) %>%
    metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

Playlists_cv %>%
    mutate(pred = map(splits, predict_forest)) %>%
    unnest(pred) %>%
    metric_set(accuracy, kap, j_index)(truth = playlist, estimate = .pred_class)

```

***

The 4 tables on the left show the accuracy of the different classification algorithms.

The accuracy showedthat k-nearest neighbour doesn't do that well. All the others perform about the same, with Random forest doing slightly better. Also we saw that k-nearest neighbour improved after only the important features according to the random forest were used being: Danceability + c04 + duration + tempo + loudness

The tables below this text show the confusion matrixes, where we can see the amount of wrong and correct predictions for my favourites, alex's favoroutes and the discover weekly week 8 playlist. Also from these tables we can see that every algorithm is the best at correctly predicting songs that belong to my favorites. Why this is the case, I'm not sure.


**K-nearest Neighbour**

|            |           | Truth |           |           |
|------------|:-----------|:-------:|-----------:|-----------:|
|            |           |Alex's Favorites | Discover_weekly8 | My Favorites|
| Prediction| Alex's Favorites     | <span style="color:green">17</span>| <span style="color:red">13</span> | <span style="color:red">10</span> |
|            | Discover_weekly8 | <span style="color:red">9</span>   | <span style="color:green">16</span>  | <span style="color:red">2</span> |
|            | My Favorites | <span style="color:red">4</span>   | <span style="color:red">1</span>  | <span style="color:green">18</span> |


**Multinomial Regression**

|            |           | Truth |           |           |
|------------|:-----------|:-------:|-----------:|-----------:|
|            |           |Alex's Favorites | Discover_weekly8 | My Favorites|
| Prediction | Alex's Favorites     | <span style="color:green">15</span>| <span style="color:red">8</span> | <span style="color:red">8</span> |
|            | Discover_weekly8 | <span style="color:red">10</span>   | <span style="color:green">19</span>  | <span style="color:red">1</span> |
|            | My Favorites | <span style="color:red">5</span>   | <span style="color:red">3</span>  | <span style="color:green">21</span> |


**Decision Trees**

|            |           | Truth |           |           |
|------------|:-----------|:-------:|-----------:|-----------:|
|            |           |Alex's Favorites | Discover_weekly8 | My Favorites|
|Prediction| Alex's Favorites     | <span style="color:green">16</span>| <span style="color:red">8</span> | <span style="color:red">5</span> |
|            | Discover_weekly8 | <span style="color:red">8</span>   | <span style="color:green">19</span>  | <span style="color:red">0</span> |
|            | My Favorites | <span style="color:red">6</span>   | <span style="color:red">3</span>  | <span style="color:green">25</span> |


**Random Forest**

|            |           | Truth |           |           |
|------------|:-----------|:-------:|-----------:|-----------:|
|            |           |Alex's Favorites | Discover_weekly8 | My Favorites|
| Prediction | Alex's Favorites     | <span style="color:green">12</span>| <span style="color:red">11</span> | <span style="color:red">4</span> |
|            | Discover_weekly8 | <span style="color:red">12</span>   | <span style="color:green">17</span>  | <span style="color:red">1</span> |
|            | My Favorites | <span style="color:red">6</span>   | <span style="color:red">2</span>  | <span style="color:green">25</span> |


**K-nearest Neighbour with danceability + c04 + duration + tempo + loudness**

|            |           | Truth |           |           |
|------------|:-----------|:-------:|-----------:|-----------:|
|            |           |Alex's Favorites | Discover_weekly8 | My Favorites|
| Prediction| Alex's Favorites     | <span style="color:green">17</span>| <span style="color:red">10</span> | <span style="color:red">9</span> |
|            | Discover_weekly8 | <span style="color:red">6</span>   | <span style="color:green">16</span>  | <span style="color:red">2</span> |
|            | My Favorites | <span style="color:red">7</span>   | <span style="color:red">4</span>  | <span style="color:green">19</span> |


### **V: Novelty functions, Delta-Chroma and Delta-Delta-Timbre for Lacrimosa & Brainstorm.**

```{r}

brain <-
    get_tidy_audio_analysis("4GdOWNJzpTWoKdA4LEbXDa") %>%
    select(segments) %>% unnest(segments)

lacrimosa_novelty <-
    get_tidy_audio_analysis("1UvaZaHkh3D9AkmBrrnbFg") %>%
    select(segments) %>% unnest(segments)

lacrimosa_novelty %>%
    mutate(loudness_max_time = start + loudness_max_time) %>%
    arrange(loudness_max_time) %>%
    mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
    ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
    geom_line() +
    xlim(0, 30) + # You can change the x limit, to change the section of the song where you want to look at.
    theme_minimal() +
    labs(x = 'Time (s)', y = 'Novelty', title="Lacrimosa Novelty Function Until 30s")


brain %>%
    mutate(loudness_max_time = start + loudness_max_time) %>%
    arrange(loudness_max_time) %>%
    mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
    ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
    geom_line() +
    xlim(0, 60) + # You can change the x limit, to change the section of the song where you want to look at.
    theme_minimal() +
    labs(x = 'Time (s)', y = 'Novelty', title="Brainstorm Novelty Function Until 60s")

lacrimosa_novelty %>%
    mutate(loudness_max_time = start + loudness_max_time) %>%
    arrange(loudness_max_time) %>%
    mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
    ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
    geom_line() +
    xlim(26, 52) + # You can change the x limit, to change the section of the song where you want to look at.
    theme_minimal() +
    labs(x = 'Time (s)', y = 'Novelty', title="Lacrimosa Novelty Function From 26s: Vocal Buildup")

brain %>%
    mutate(loudness_max_time = start + loudness_max_time) %>%
    arrange(loudness_max_time) %>%
    mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
    ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
    geom_line() +
    xlim(60, 110) + # You can change the x limit, to change the section of the song where you want to look at.
    theme_minimal() +
    labs(x = 'Time (s)', y = 'Novelty', title="Brainstorm Novelty Function From 60s: Buildup")


lacrimosa_novelty%>% # These are just deltas
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>%
    arrange(start) %>%
    mutate(pitches = map2(pitches, lag(pitches), `-`)) %>%
    compmus_gather_chroma %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = pitch_class,
            fill = pmax(0, value))) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    xlim(0, 30) +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude',  title="Lacrimosa Delta-Chroma") +
    theme_classic()

brain%>% # These are just deltas
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>%
    arrange(start) %>%
    mutate(pitches = map2(pitches, lag(pitches), `-`)) %>%
    compmus_gather_chroma %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = pitch_class,
            fill = pmax(0, value))) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    xlim(0, 30) +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude',  title="Brainstorm Delta-Chroma") +
    theme_classic()


lacrimosa_novelty %>%  # These are delta deltaas: To get delta deltas je change the lag in the 3d rule.
    arrange(start) %>%
    mutate(timbre = map2(timbre, lag(timbre), `-`)) %>%
    compmus_gather_timbre %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = basis,
            fill = pmax(0, value))) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    xlim(0, 30) +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude', title="Lacrimosa Delta-Delta-Timbre") +
    theme_classic()


brain %>%  # These are delta deltaas: To get delta deltas je change the lag in the 3d rule.
    arrange(start) %>%
    mutate(timbre = map2(timbre, lag(timbre), `-`)) %>%
    compmus_gather_timbre %>%
    ggplot(
        aes(
            x = start + duration / 2,
            width = duration,
            y = basis,
            fill = pmax(0, value))) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    xlim(0, 30) +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude',  title="Brainstorm Delta-Delta-Timbre") +
    theme_classic()




```

***

__Lacrimosa__:
For Lacrimosa it's not very consistent, the first novelty plot show the first 30s, which start with 10s of only violin and then the vocals come in.

The second novelty plot start from round 27s till 52 seconds, here you get a slow buildup with some vocals, where it's also hard for the novelty function to work. I guess that it's not surprising as this song doesnt have any percussion or an obvios beat. It is mostly string music and vocals.

The delta chroma-gram shows activation for B, which is weird. As the song is in Dminor there shouldn't even be a B in here, it should be a Bb. This might be because of the mistuning. 

The delta-delta timbre-gram shows only a change in component 4. Meaning that if we look at the change of the change, appareantly component 4 plays a big role.

__Brainstorm__:
We can see that the novelty function for Braisntorm is working quite well. The first novelty plot shows that there is a very regular beat and at 30 second, the bass of the beat becomes even louder and more obvious which we can see in the plot. There are also some high heads, which are the smaller peaks we see in the plot.

The second novelty function shows the song from 60s. At this part the beat completely dissapears and some low bassy sounds are coming through, but quite beatless. This can also be seen from the novelty function, as it doesn't really get what's going on. From around 70s untill 101s the beat slowly builds up again, as we can see from the novelty function, as it's realizing what to do again.


The Delta Chromagram for Brainstorm doesn't show very obvious patterns, which isn't weird as the song consist of a lot of bass. It basically shows nothing at all.


The delta-delta TimbreGram for Brainstorm shows us some activity around c04 and the delta-delta Timbregram Meaning that the change of the change is most active around c04.
